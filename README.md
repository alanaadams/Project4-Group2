# Project 4 - Group 2: Predicting Housing Prices

Welcome to the official GitHub page for Project 4 by Group 2. This project aims to predict housing prices leveraging various datasets and machine learning methodologies.

## Overview

**Problem Statement**: Our goal is to construct a regression model capable of predicting housing prices based on distinct features such as location, size, amenities, etc. Our solution aims to empower buyers, sellers, and real estate agents with informed decision-making capabilities.

## Team Members
- **Alana Adams**
- **Michael Lohr**
- **Bryce Deering**

## Datasets & Technologies
1. **House Sales in King County, USA Dataset**: [Kaggle Dataset](https://www.kaggle.com/harlfoxem/housesalesprediction)
2. **Python Pandas**: [Official Documentation](https://pandas.pydata.org/)
3. **Python Scikit-learn**: [Official Documentation](https://scikit-learn.org/)

## Workflow

1. **Data Preprocessing**: Using Pandas to load, preprocess, clean, handle missing values, encode categorical variables, and scale features from the housing dataset.
2. **Data Split**: Segmenting the dataset into training and testing sets.
3. **Model Training**: Constructing a regression model (e.g., linear regression, random forest regressor, or gradient boosting regressor) using Scikit-learn.
4. **Model Evaluation**: Analyzing model's performance using metrics like MSE, RMSE, or R-squared.
5. **Web App Development**: Crafting a web application with HTML/CSS/Bootstrap and JavaScript to allow users to specify property details and receive price predictions.
6. **API Deployment**: Operationalizing the trained model via a REST API using Flask or Django, which will then be integrated into the web application.
7. **Data Visualization**: Implementing JavaScript Plotly or Python Matplotlib to visualize housing price trends, crucial features, and prediction accuracy.

## Requirements & Grading Criteria

### Data Model Implementation (25 points)
- **Python script**: Initializes, trains, and evaluates a model (10 points).
- **Data Preprocessing**: Data is refined, normalized, and standardized (5 points).
- **Data Retrieval**: Model fetches data from SQL or Spark (5 points).
- **Performance Metrics**: Model showcases at least 75% classification accuracy or 0.80 R-squared (5 points).

### Data Model Optimization (25 points)
- **Documentation**: Model optimization & evaluation process documented in a CSV/Excel table or within Python script (15 points).
- **Performance Display**: Display of overall model performance at the script's conclusion (10 points).

### GitHub Documentation (25 points)
- **Repository Structure**: GitHub repo is streamlined, free of extraneous files, and leverages an appropriate `.gitignore` (10 points).
- **README Quality**: A comprehensive and polished README representing the project's content (15 points).

### Group Presentation (25 points)
- **Participation**: Participation of all group members during the presentation (5 points).
- **Flow**: Smooth content flow, transitions, and conclusions within time limits (5 points).
- **Content Alignment**: Presentation strictly aligns with the project's content (10 points).
- **Engagement**: Engaging content that captivates the audience (5 points).

---
- **Project Proposal**: For a more detailed understanding of our project, check out our [Project Proposal](https://docs.google.com/document/d/11aaJE0Xezc9KbzMVungdk57z9aFXixJTesiDrbiiAy8/edit?usp=sharing).
- **Presentation**: For a more detailed walkthrough of our project, check out our [Google Presentation](https://docs.google.com/presentation/d/1uoPLtZ--Qi85bl6fBkhplk0M61xqqOZdF_-C47hG83c/edit?usp=sharing).

